# challenge-3-pyspark
Learning basics of pyspark as a week 9-10 challenge

## Project scope
There is no specific goal to this project like building a solution or the best something. The goal is to understand PySpark better and start being somewhat productive with it. This means learning the basics of:
- SparkSession config basic options (most of them were not used as they allow connections with more services I have not used)
- loading + saving data
- DataFrame API
- aggregations
- pivoting
- UDFs (user defined functions)
- more advanced aggregations like rollup, cube etc.
- window functions
- Spark SQL

## Data
The only dataset used in this project is a kaggle dataset with Lichess games ([link](https://www.kaggle.com/datasets/datasnaek/chess/data)). It contains information about around 20,000 games with columns describing start time, end time, opening for both players, game time format etc.